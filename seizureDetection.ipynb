{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "PJrZqqZm9iSQ",
    "outputId": "6388b1b2-9c68-4785-bb3d-fa1cf227b7b5"
   },
   "outputs": [],
   "source": [
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "!curl https://sdk.cloud.google.com | bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "cCrvKb9W-LRE",
    "outputId": "37bc023a-850c-4dff-ab1f-e8b87c2f0df2"
   },
   "outputs": [],
   "source": [
    "!gcloud init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zd-gwOyP-ltn",
    "outputId": "a453599c-51b3-4abc-dd63-cf55eed3a026"
   },
   "outputs": [],
   "source": [
    "!gsutil -m cp -r gs://chbmit-1.0.0.physionet.org ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "id": "3Zmtkte3ISG7",
    "outputId": "6aff05f8-3448-4925-de5c-3345a5b6f259"
   },
   "outputs": [],
   "source": [
    "pip install pyedflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mrJpduW28twS"
   },
   "outputs": [],
   "source": [
    "import pyedflib\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from scipy.signal import butter, lfilter\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import  Dense, Conv3D, Dropout, Flatten, BatchNormalization \n",
    "from keras.callbacks import EarlyStopping\n",
    "from random import shuffle\n",
    "import math\n",
    "import numpy as np\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5O1JGgONPIvo"
   },
   "outputs": [],
   "source": [
    "\n",
    "# DATASET: https://physionet.org/pn6/chbmit/\n",
    "sampleRate = 256\n",
    "pathDataSet = '/content/chbmit-1.0.0.physionet.org/'# path of the dataset\n",
    "FirstPartPathOutput='/content/spectrograms' #path where the spectogram will be saved\n",
    "#uncomment below lines if you want to run on more patients and use the same data in further\n",
    "#steps\n",
    "#patients = [\"01\", \"02\", \"03\", \"05\", \"09\", \"10\", \"13\", \"14\", \"18\", \"19\", \"20\", \"21\", \"23\"]\n",
    "#nSeizure = [7, 3, 6, 5, 4, 6, 5, 5, 6, 3, 5, 4, 5]\n",
    "patients = [\"01\",\"02\"]\n",
    "_30_MINUTES_OF_DATA = 256*60*30\n",
    "_MINUTES_OF_DATA_BETWEEN_PRE_AND_SEIZURE = 3 #In teoria 5 come l'SPH ma impostato a 3 per considerare alcune seizure prese nel paper\n",
    "_MINUTES_OF_PREICTAL = 30\n",
    "_SIZE_WINDOW_IN_SECONDS = 30\n",
    "_SIZE_WINDOW_SPECTOGRAM = _SIZE_WINDOW_IN_SECONDS*256\n",
    "nSpectogram=0\n",
    "signalsBlock=None\n",
    "SecondPartPathOutput=''\n",
    "legendOfOutput=''\n",
    "isPreictal=''\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2BtcG0bjRmP7"
   },
   "outputs": [],
   "source": [
    "def loadParametersFromFile(filePath):\n",
    "    global pathDataSet\n",
    "    global FirstPartPathOutput\n",
    "    if(os.path.isfile(filePath)):\n",
    "        with open(filePath, \"r\") as f:\n",
    "                line=f.readline()\n",
    "                if(line.split(\":\")[0]==\"pathDataSet\"):\n",
    "                    pathDataSet=line.split(\":\")[1].strip()\n",
    "                line=f.readline()\n",
    "                if(line.split(\":\")[0]==\"FirstPartPathOutput\"):\n",
    "                    FirstPartPathOutput=line.split(\":\")[1].strip()\n",
    "                \n",
    "\n",
    "def butter_bandstop_filter(data, lowcut, highcut, fs, order):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "\n",
    "    i, u = butter(order, [low, high], btype='bandstop')\n",
    "    y = lfilter(i, u, data)\n",
    "    return y\n",
    "\n",
    "def butter_highpass_filter(data, cutoff, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = butter(order, normal_cutoff, btype='high', analog=False)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "def loadSummaryPatient(index):\n",
    "    f = open(pathDataSet+'chb'+patients[index]+'/chb'+patients[index]+'-summary.txt', 'r')\n",
    "    return f\n",
    "\n",
    "\n",
    "def loadDataOfPatient(indexPatient, fileOfData):\n",
    "    f = pyedflib.EdfReader(pathDataSet+'chb'+patients[indexPatient]+'/'+fileOfData)  # https://pyedflib.readthedocs.io/en/latest/#description\n",
    "    n = f.signals_in_file\n",
    "    sigbufs = np.zeros((n, f.getNSamples()[0]))\n",
    "    for i in np.arange(n):\n",
    "        sigbufs[i, :] = f.readSignal(i)\n",
    "    sigbufs=cleanData(sigbufs, indexPatient)\n",
    "    return sigbufs\n",
    "\n",
    "def cleanData(Data, indexPatient):\n",
    "    if(patients[indexPatient] in [\"19\"]):\n",
    "        Data=np.delete(Data, 22, axis=0)\n",
    "        Data=np.delete(Data, 17, axis=0)\n",
    "        Data=np.delete(Data, 12, axis=0)\n",
    "        Data=np.delete(Data, 9, axis=0)\n",
    "        Data=np.delete(Data, 4, axis=0)\n",
    "    return Data\n",
    "\n",
    "\n",
    "def getTime(dateInString):\n",
    "    time=0\n",
    "    try:\n",
    "        time = datetime.strptime(dateInString, '%H:%M:%S')\n",
    "    except ValueError:\n",
    "        dateInString=\" \"+dateInString\n",
    "        if(' 24' in dateInString):\n",
    "            dateInString = dateInString.replace(' 24', '23')\n",
    "            time = datetime.strptime(dateInString, '%H:%M:%S')\n",
    "            time += timedelta(hours=1)\n",
    "        else:\n",
    "            dateInString = dateInString.replace(' 25', '23')\n",
    "            time = datetime.strptime(dateInString, '%H:%M:%S')\n",
    "            time += timedelta(hours=2)\n",
    "    return time\n",
    "\n",
    "def saveSignalsOnDisk(signalsBlock, nSpectogram):\n",
    "    global SecondPartPathOutput\n",
    "    global FirstPartPathOutput\n",
    "    global legendOfOutput\n",
    "    global isPreictal\n",
    "\n",
    "    if not os.path.exists(FirstPartPathOutput):\n",
    "        os.makedirs(FirstPartPathOutput)\n",
    "    if not os.path.exists(FirstPartPathOutput+SecondPartPathOutput):\n",
    "        os.makedirs(FirstPartPathOutput+SecondPartPathOutput) \n",
    "    np.save(FirstPartPathOutput+SecondPartPathOutput+'/spec_'+isPreictal+'_'+str(nSpectogram-signalsBlock.shape[0])+'_'+str(nSpectogram-1), signalsBlock)\n",
    "    legendOfOutput=legendOfOutput+str(nSpectogram-signalsBlock.shape[0])+' '+str(nSpectogram-1) +' '+SecondPartPathOutput+'/spec_'+isPreictal+'_'+str(nSpectogram-signalsBlock.shape[0])+'_'+str(nSpectogram-1) +'.npy\\n'\n",
    "\n",
    "\n",
    "\n",
    "def createSpectrogram(data, S=0):\n",
    "    global nSpectogram\n",
    "    global signalsBlock\n",
    "    global inB\n",
    "    signals=np.zeros((22,59,114))\n",
    "    \n",
    "    t=0\n",
    "    movement=int(S*256)\n",
    "    if(S==0):\n",
    "        movement=_SIZE_WINDOW_SPECTOGRAM        \n",
    "    while data.shape[1]-(t*movement+_SIZE_WINDOW_SPECTOGRAM) > 0:\n",
    "        \n",
    "        for i in range(0, 22):\n",
    "            start = t*movement\n",
    "            stop = start+_SIZE_WINDOW_SPECTOGRAM\n",
    "            signals[i,:]=createSpec(data[i,start:stop])\n",
    "        if(signalsBlock is None):\n",
    "            signalsBlock=np.array([signals])\n",
    "        else:\n",
    "            signalsBlock=np.append(signalsBlock, [signals], axis=0)\n",
    "        nSpectogram=nSpectogram+1\n",
    "        if(signalsBlock.shape[0]==50):\n",
    "            saveSignalsOnDisk(signalsBlock, nSpectogram)\n",
    "            signalsBlock=None\n",
    "             \n",
    "        t = t+1\n",
    "    return (data.shape[1]-t*_SIZE_WINDOW_SPECTOGRAM)*-1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MnpDqL2OUJqd"
   },
   "outputs": [],
   "source": [
    "def createSpec(data):\n",
    "    fs=256\n",
    "    lowcut=117\n",
    "    highcut=123\n",
    "\n",
    "    y=butter_bandstop_filter(data, lowcut, highcut, fs, order=6)\n",
    "    lowcut=57\n",
    "    highcut=63\n",
    "    y=butter_bandstop_filter(y, lowcut, highcut, fs, order=6)\n",
    "    \n",
    "    cutoff=1\n",
    "    y=butter_highpass_filter(y, cutoff, fs, order=6)\n",
    "    \n",
    "    Pxx=signal.spectrogram(y, nfft=256, fs=256, return_onesided=True, noverlap=128)[2]    \n",
    "    Pxx = np.delete(Pxx, np.s_[117:123+1], axis=0)\n",
    "    Pxx = np.delete(Pxx, np.s_[57:63+1], axis=0)\n",
    "    Pxx = np.delete(Pxx, 0, axis=0)\n",
    "    \n",
    "    result=(10*np.log10(np.transpose(Pxx))-(10*np.log10(np.transpose(Pxx))).min())/(10*np.log10(np.transpose(Pxx))).ptp()\n",
    "    return result\n",
    "\n",
    "def createSpecAndPlot(data):\n",
    "    freqs, bins,Pxx =signal.spectrogram(data, nfft=256, fs=256, return_onesided=True, noverlap=128)\n",
    "    \n",
    "    print(\"Original\")\n",
    "    plt.pcolormesh(freqs, bins, 10*np.log10(np.transpose(Pxx)),cmap=plt.cm.jet)\n",
    "    plt.colorbar()\n",
    "    plt.ylabel('sec')\n",
    "    plt.xlabel('Hz')\n",
    "    plt.title('Spettrogramma') \n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "    fs=256\n",
    "    lowcut=117\n",
    "    highcut=123\n",
    "\n",
    "    y=butter_bandstop_filter(data, lowcut, highcut, fs, order=6)\n",
    "    lowcut=57\n",
    "    highcut=63\n",
    "    y=butter_bandstop_filter(y, lowcut, highcut, fs, order=6)\n",
    "    \n",
    "    cutoff=1\n",
    "    y=butter_highpass_filter(y, cutoff, fs, order=6)\n",
    "    \n",
    "    #Pxx=signal.spectrogram(y, nfft=256, fs=256, return_onesided=True, noverlap=128)[2]\n",
    "    freqs, bins,Pxx =signal.spectrogram(y, nfft=256, fs=256, return_onesided=True, noverlap=128)\n",
    "    \n",
    "    print(\"Filtered\")\n",
    "    plt.pcolormesh(freqs, bins, 10*np.log10(np.transpose(Pxx)),cmap=plt.cm.jet)\n",
    "    plt.colorbar()\n",
    "    plt.ylabel('sec')\n",
    "    plt.xlabel('Hz')\n",
    "    plt.title('Spettrogramma')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "    Pxx = np.delete(Pxx, np.s_[117:123+1], axis=0)\n",
    "    Pxx = np.delete(Pxx, np.s_[57:63+1], axis=0)\n",
    "    Pxx = np.delete(Pxx, 0, axis=0)\n",
    "    \n",
    "    print(\"Cleaned but not standard\")\n",
    "    freqs = np.arange(Pxx.shape[0])\n",
    "    plt.pcolormesh(freqs, bins, 10*np.log10(np.transpose(Pxx)),cmap=plt.cm.jet)\n",
    "    plt.colorbar()\n",
    "    plt.ylabel('sec')\n",
    "    plt.xlabel('Hz')\n",
    "    plt.title('Spettrogramma') \n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    result=(10*np.log10(np.transpose(Pxx))-(10*np.log10(np.transpose(Pxx))).min())/(10*np.log10(np.transpose(Pxx))).ptp()\n",
    "    \n",
    "    print(\"Standard\")\n",
    "    freqs = np.arange(result.shape[1])\n",
    "    plt.pcolormesh(freqs, bins, result,cmap=plt.cm.jet)\n",
    "    plt.colorbar()\n",
    "    plt.ylabel('sec')\n",
    "    plt.xlabel('Hz')\n",
    "    plt.title('Spettrogramma') \n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QmBWqkWJUZbv"
   },
   "outputs": [],
   "source": [
    "class PreIntData:\n",
    "    start=0\n",
    "    end=0\n",
    "    def __init__(self, s, e):\n",
    "        self.start=s\n",
    "        self.end=e\n",
    "       \n",
    "class FileData:\n",
    "    start=0\n",
    "    end=0\n",
    "    nameFile=\"\"\n",
    "    def __init__(self, s, e, nF):\n",
    "        self.start=s\n",
    "        self.end=e\n",
    "        self.nameFile=nF\n",
    "\n",
    "\n",
    "\n",
    "def createArrayIntervalData(fSummary):\n",
    "    preictalInteval=[]\n",
    "    interictalInterval=[]\n",
    "    interictalInterval.append(PreIntData(datetime.min, datetime.max))\n",
    "    files=[]\n",
    "    firstTime=True\n",
    "    oldTime=datetime.min\n",
    "    startTime=0\n",
    "    line=fSummary.readline()\n",
    "    endS=datetime.min\n",
    "    while(line):\n",
    "        data=line.split(':')\n",
    "        if(data[0]==\"File Name\"):\n",
    "            nF=data[1].strip()\n",
    "            s=getTime((fSummary.readline().split(\": \"))[1].strip())\n",
    "            if(firstTime):\n",
    "                interictalInterval[0].start=s\n",
    "                firstTime=False\n",
    "                startTime=s\n",
    "            while s<oldTime:\n",
    "                s=s+ timedelta(hours=24)\n",
    "            oldTime=s\n",
    "            endTimeFile=getTime((fSummary.readline().split(\": \"))[1].strip())\n",
    "            while endTimeFile<oldTime:\n",
    "                endTimeFile=endTimeFile+ timedelta(hours=24)\n",
    "            oldTime=endTimeFile\n",
    "            files.append(FileData(s, endTimeFile,nF))\n",
    "            for j in range(0, int((fSummary.readline()).split(':')[1])):\n",
    "                secSt=int(fSummary.readline().split(': ')[1].split(' ')[0])\n",
    "                secEn=int(fSummary.readline().split(': ')[1].split(' ')[0])\n",
    "                ss=s+timedelta(seconds=secSt)- timedelta(minutes=_MINUTES_OF_DATA_BETWEEN_PRE_AND_SEIZURE+_MINUTES_OF_PREICTAL)\n",
    "                if((len(preictalInteval)==0 or ss > endS) and ss-startTime>timedelta(minutes=20)):\n",
    "                    ee=ss+ timedelta(minutes=_MINUTES_OF_PREICTAL) \n",
    "                    preictalInteval.append(PreIntData(ss,ee))\n",
    "                endS=s+timedelta(seconds=secEn)\n",
    "                ss=s+timedelta(seconds=secSt)- timedelta(hours=4) \n",
    "                ee=s+timedelta(seconds=secEn)+ timedelta(hours=4) \n",
    "                if(interictalInterval[len(interictalInterval)-1].start<ss and interictalInterval[len(interictalInterval)-1].end>ee):\n",
    "                    interictalInterval[len(interictalInterval)-1].end=ss\n",
    "                    interictalInterval.append(PreIntData(ee, datetime.max))\n",
    "                else:\n",
    "                    if(interictalInterval[len(interictalInterval)-1].start<ee):\n",
    "                        interictalInterval[len(interictalInterval)-1].start=ee\n",
    "        line=fSummary.readline()\n",
    "    fSummary.close()\n",
    "    interictalInterval[len(interictalInterval)-1].end=endTimeFile\n",
    "    return preictalInteval, interictalInterval, files\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 721
    },
    "id": "bfm90JV6RqBJ",
    "outputId": "b21196ad-3e28-49b2-c81e-08e7a3681859"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    global SecondPartPathOutput\n",
    "    global FirstPartPathOutput\n",
    "    global legendOfOutput\n",
    "    global nSpectogram\n",
    "    global signalsBlock\n",
    "    global isPreictal\n",
    "    print(\"START \\n\")\n",
    "    loadParametersFromFile(\"PARAMETERS_DATA_EDITING.txt\")\n",
    "    print(\"Parameters loaded\")\n",
    "    \n",
    "    for indexPatient in range(0, len(patients)):\n",
    "        print(\"Working on patient \"+patients[indexPatient])\n",
    "        legendOfOutput=\"\"\n",
    "        allLegend=\"\"\n",
    "        nSpectogram=0\n",
    "        \n",
    "        SecondPartPathOutput='/paz'+patients[indexPatient]\n",
    "        f = loadSummaryPatient(indexPatient)\n",
    "        preictalInfo, interictalInfo, filesInfo=createArrayIntervalData(f)\n",
    "        if(patients[indexPatient]==\"19\"):\n",
    "            preictalInfo.pop(0) \n",
    "        print(\"Summary patient loaded\")\n",
    "        \n",
    "       \n",
    "        print(\"START creation interictal spectrogram\")\n",
    "        totInst=0\n",
    "        #c=0\n",
    "        #d=0   \n",
    "        interictalData = np.array([]).reshape(22,0)       \n",
    "        indexInterictalSegment=0      \n",
    "        isPreictal=''\n",
    "        for fInfo in filesInfo:\n",
    "            fileS=fInfo.start\n",
    "            fileE=fInfo.end\n",
    "            intSegStart=interictalInfo[indexInterictalSegment].start\n",
    "            intSegEnd=interictalInfo[indexInterictalSegment].end\n",
    "            while(fileS>intSegEnd and indexInterictalSegment<len(interictalInfo)):\n",
    "                indexInterictalSegment=indexInterictalSegment+1\n",
    "                intSegStart=interictalInfo[indexInterictalSegment].start\n",
    "                intSegEnd=interictalInfo[indexInterictalSegment].end\n",
    "            start=0\n",
    "            end=0\n",
    "            if(not fileE<intSegStart or fileS>intSegEnd):\n",
    "                if(fileS>=intSegStart):\n",
    "                    start=0\n",
    "                else:\n",
    "                    start=(intSegStart-fileS).seconds\n",
    "                if(fileE<=intSegEnd):\n",
    "                    end=None\n",
    "                else:\n",
    "                    end=(intSegEnd-fileS).seconds\n",
    "                tmpData=loadDataOfPatient(indexPatient, fInfo.nameFile)\n",
    "                if(not end==None):\n",
    "                    end=end*256\n",
    "                if(tmpData.shape[0]<22):\n",
    "                    print(patients[indexPatient] +\"  HA UN NUMERO MINORE DI CANALI\")\n",
    "                else:\n",
    "                    interictalData=np.concatenate((interictalData, tmpData[0:22,start*256:end]), axis=1)\n",
    "                    notUsed= createSpectrogram(interictalData)\n",
    "                    totInst+=interictalData.shape[1]/256-notUsed/256       \n",
    "                    interictalData = np.delete(interictalData, np.s_[0:interictalData.shape[1]-notUsed], axis=1)\n",
    "                    \n",
    "        S=(_SIZE_WINDOW_IN_SECONDS*(len(preictalInfo)*_MINUTES_OF_PREICTAL*60-_SIZE_WINDOW_IN_SECONDS*len(preictalInfo)))/totInst \n",
    "        if(not (signalsBlock is None)):  \n",
    "            saveSignalsOnDisk(signalsBlock, nSpectogram)\n",
    "        signalsBlock=None\n",
    "            \n",
    "        print(\"Spectrogram interictal: \"+ str(nSpectogram))\n",
    "        print(\"Hours interictal: \" +str(totInst/60/60))\n",
    "        legendOfOutput=str(nSpectogram)+\"\\n\"+legendOfOutput\n",
    "        legendOfOutput=\"INTERICTAL\"+\"\\n\"+legendOfOutput\n",
    "        legendOfOutput=\"SEIZURE: \" +str(len(preictalInfo))+\"\\n\"+legendOfOutput\n",
    "        legendOfOutput=patients[indexPatient]+\"\\n\"+legendOfOutput\n",
    "        allLegend=legendOfOutput\n",
    "        legendOfOutput=''\n",
    "        nSpectogram=0\n",
    "        print(\"END creation interictal spectrogram\")\n",
    "        \n",
    "        print(\"START creation preictal spectrogram\")\n",
    "        isPreictal='P'\n",
    "        contSeizure=-1\n",
    "        for pInfo in preictalInfo:\n",
    "            contSeizure=contSeizure+1\n",
    "            legendOfOutput=legendOfOutput+\"SEIZURE \"+str(contSeizure)+\"\\n\"\n",
    "            preictalData = np.array([]).reshape(22,0)\n",
    "            j=0\n",
    "            for j in range(0,len(filesInfo)):\n",
    "                if(pInfo.start>=filesInfo[j].start and pInfo.start<filesInfo[j].end):\n",
    "                    break\n",
    "            start=(pInfo.start-filesInfo[j].start).seconds\n",
    "            if(start<0):\n",
    "                start=0 \n",
    "            end=None\n",
    "            tmpData=[]\n",
    "            if(pInfo.end<=filesInfo[j].end):\n",
    "                end=(pInfo.end-filesInfo[j].start).seconds\n",
    "                tmpData=loadDataOfPatient(indexPatient, filesInfo[j].nameFile)\n",
    "                preictalData=np.concatenate((preictalData, tmpData[0:22,start*256:end*256]), axis=1)\n",
    "            else:\n",
    "                tmpData=loadDataOfPatient(indexPatient, filesInfo[j].nameFile)\n",
    "                preictalData=np.concatenate((preictalData, tmpData[0:22,start*256:]), axis=1)\n",
    "                end=(pInfo.end-filesInfo[j+1].start).seconds\n",
    "                tmpData=loadDataOfPatient(indexPatient, filesInfo[j+1].nameFile)\n",
    "                preictalData=np.concatenate((preictalData, tmpData[0:22,0:end*256]), axis=1)\n",
    "            notUsed= createSpectrogram(preictalData, S=S)\n",
    "            if(not (signalsBlock is None)): \n",
    "                saveSignalsOnDisk(signalsBlock, nSpectogram)\n",
    "            signalsBlock=None\n",
    "        \n",
    "        allLegend=allLegend+\"\\n\"+\"PREICTAL\"+\"\\n\"+str(nSpectogram)+\"\\n\"+legendOfOutput\n",
    "        print(\"Spectrogram preictal: \"+ str(nSpectogram))\n",
    "        print(\"SEIZURE: \" +str(len(preictalInfo)))\n",
    "        print(\"END creation preictal spectrogram\")\n",
    "        \n",
    "        print(\"START creation \\'real\\' preictal spectrogram\")\n",
    "        isPreictal='P_R'\n",
    "        nSpectogram=0\n",
    "        contSeizure=-1\n",
    "        S=0\n",
    "        legendOfOutput=''\n",
    "        for pInfo in preictalInfo:\n",
    "            contSeizure=contSeizure+1\n",
    "            legendOfOutput=legendOfOutput+\"SEIZURE \"+str(contSeizure)+\"\\n\"\n",
    "            preictalData = np.array([]).reshape(22,0)\n",
    "            j=0\n",
    "            for j in range(0,len(filesInfo)):\n",
    "                if(pInfo.start>=filesInfo[j].start and pInfo.start<filesInfo[j].end):\n",
    "                    break\n",
    "            start=(pInfo.start-filesInfo[j].start).seconds\n",
    "            if(start<0):\n",
    "                start=0\n",
    "            end=None\n",
    "            tmpData=[]\n",
    "            if(pInfo.end<=filesInfo[j].end):\n",
    "                end=(pInfo.end-filesInfo[j].start).seconds\n",
    "                tmpData=loadDataOfPatient(indexPatient, filesInfo[j].nameFile)\n",
    "                preictalData=np.concatenate((preictalData, tmpData[0:22,start*256:end*256]), axis=1)\n",
    "            else:\n",
    "                tmpData=loadDataOfPatient(indexPatient, filesInfo[j].nameFile)\n",
    "                preictalData=np.concatenate((preictalData, tmpData[0:22,start*256:]), axis=1)\n",
    "                end=(pInfo.end-filesInfo[j+1].start).seconds\n",
    "                tmpData=loadDataOfPatient(indexPatient, filesInfo[j+1].nameFile)\n",
    "                preictalData=np.concatenate((preictalData, tmpData[0:22,0:end*256]), axis=1)\n",
    "            notUsed= createSpectrogram(preictalData, S=S)\n",
    "            if(not (signalsBlock is None)): \n",
    "                saveSignalsOnDisk(signalsBlock, nSpectogram)\n",
    "            signalsBlock=None\n",
    "        \n",
    "        allLegend=allLegend+\"\\n\"+\"REAL_PREICTAL\"+\"\\n\"+str(nSpectogram)+\"\\n\"+legendOfOutput\n",
    "        print(\"Spectrogram \\'REAL\\' preictal: \"+ str(nSpectogram))\n",
    "        print(\"END creation \\'real\\' preictal spectrogram\")\n",
    "\n",
    "        \n",
    "        text_file = open(FirstPartPathOutput+SecondPartPathOutput+\"/legendAllData.txt\", \"w\")\n",
    "        text_file.write(allLegend)\n",
    "        text_file.close()\n",
    "        print(\"Legend saved on disk\")\n",
    "        print('\\n')\n",
    "    print(\"END\")\n",
    "            \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "id": "TJ5Hmws4TeQi",
    "outputId": "8d43842f-198a-4e06-dcf3-5be1f2247a9e"
   },
   "outputs": [],
   "source": [
    "img=np.load('/content/spectrograms/paz02/spec_P_100_149.npy')\n",
    "\n",
    "\n",
    "plt.imshow(img[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "id": "C5q1EAl1zNeO",
    "outputId": "d3fc94cc-43ed-43d3-99b3-6701c90fd62a"
   },
   "outputs": [],
   "source": [
    "plt.imshow(img[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-1qRe_TSmxXd",
    "outputId": "c26b8cc4-87f9-416f-b2d3-2788f3296ec8"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "PathSpectogramFolder='/content/spectrograms'\n",
    "OutputPath='/content/results.txt'\n",
    "OutputPathModels='/content/chbmit-1.0.0.physionet.org'\n",
    "interictalSpectograms=[]\n",
    "preictalSpectograms=[]  #This array contains syntetic data, it's created to have a balance dataset and it's used for training\n",
    "preictalRealSpectograms=[]  #This array containt the real preictal data, it's used for testing\n",
    "#use patients list selected in the begining\n",
    "patients = [\"01\", \"02\"]\n",
    "nSeizure=0\n",
    "\n",
    "def loadParametersFromFile(filePath):\n",
    "    global PathSpectogramFolder\n",
    "    global OutputPath\n",
    "    global OutputPathModels\n",
    "    if(os.path.isfile(filePath)):\n",
    "        with open(filePath, \"r\") as f:\n",
    "                line=f.readline()\n",
    "                if(line.split(\":\")[0]==\"PathSpectogramFolder\"):\n",
    "                    PathSpectogramFolder=line.split(\":\")[1].strip()\n",
    "                line=f.readline()\n",
    "                if(line.split(\":\")[0]==\"OutputPath\"):\n",
    "                    OutputPath=line.split(\":\")[1].strip()\n",
    "                line=f.readline()\n",
    "                if(line.split(\":\")[0]==\"OutputPathModels\"):\n",
    "                    OutputPathModels=line.split(\":\")[1].strip()\n",
    "\n",
    "def loadSpectogramData(indexPat):\n",
    "    global interictalSpectograms\n",
    "    global preictalSpectograms\n",
    "    global preictalRealSpectograms\n",
    "    global nSeizure\n",
    "    nFileForSeizure=0\n",
    "    \n",
    "    interictalSpectograms=[]\n",
    "    preictalSpectograms=[]\n",
    "    preictalRealSpectograms=[]\n",
    "    \n",
    "    f = open(PathSpectogramFolder+'/paz'+patients[indexPat]+'/legendAllData.txt', 'r')\n",
    "    line=f.readline()\n",
    "    while(not \"SEIZURE\" in line):\n",
    "        line=f.readline()\n",
    "    nSeizure=int(line.split(\":\")[1].strip())\n",
    "    line=f.readline()\n",
    "    line=f.readline()\n",
    "    nSpectograms=int(line.strip())\n",
    "    nFileForSeizure=math.ceil(math.ceil(nSpectograms/50)/nSeizure)\n",
    "    line=f.readline()\n",
    "    \n",
    "    \n",
    "    cont=-1\n",
    "    indFilePathRead=0\n",
    "    while(\"npy\" in line and indFilePathRead<nSeizure*nFileForSeizure):\n",
    "        if(indFilePathRead%nFileForSeizure==0):\n",
    "            interictalSpectograms.append([])\n",
    "            cont=cont+1\n",
    "            interictalSpectograms[cont].append(line.split(' ')[2].rstrip())#.rstrip() remove \\n\n",
    "            indFilePathRead=indFilePathRead+1\n",
    "        else:\n",
    "            if(len(line.split(' '))>=3):\n",
    "                interictalSpectograms[cont].append(line.split(' ')[2].rstrip())\n",
    "            indFilePathRead=indFilePathRead+1\n",
    "            \n",
    "        line=f.readline()\n",
    "    line=f.readline()L\n",
    "    line=f.readline()\n",
    "    line=f.readline()\n",
    "\n",
    "   \n",
    "    cont=-1\n",
    "    indFilePathRead=0   \n",
    "     \n",
    "    while(line.strip()!=\"\"):\n",
    "        if(\"SEIZURE\" in line):\n",
    "            line=f.readline()\n",
    "            if(len(line.split(' '))>=3):\n",
    "                preictalSpectograms.append([])\n",
    "                cont=cont+1\n",
    "                preictalSpectograms[cont].append(line.split(' ')[2].rstrip())\n",
    "                indFilePathRead=indFilePathRead+1\n",
    "        else:\n",
    "            if(len(line.split(' '))>=3):\n",
    "                preictalSpectograms[cont].append(line.split(' ')[2].rstrip())\n",
    "            indFilePathRead=indFilePathRead+1\n",
    "            \n",
    "        line=f.readline()\n",
    "        \n",
    "    line=f.readline()\n",
    "    line=f.readline()\n",
    "    line=f.readline()\n",
    "\n",
    "    \n",
    "    cont=-1\n",
    "    while(line):\n",
    "        if(\"SEIZURE\" in line):\n",
    "            line=f.readline()\n",
    "            preictalRealSpectograms.append([])\n",
    "            cont=cont+1\n",
    "            preictalRealSpectograms[cont].append(line.split(' ')[2].rstrip())\n",
    "        else:\n",
    "            preictalRealSpectograms[cont].append(line.split(' ')[2].rstrip())\n",
    "            \n",
    "        line=f.readline()\n",
    "    f.close()\n",
    "\n",
    "\n",
    "def createModel():\n",
    "    input_shape=(1, 22, 59, 114)\n",
    "    model = Sequential()\n",
    "    #C1\n",
    "    model.add(Conv3D(16, (22, 5, 5), strides=(1, 2, 2), padding='valid',activation='relu',data_format= \"channels_first\", input_shape=input_shape))\n",
    "    model.add(keras.layers.MaxPooling3D(pool_size=(1, 2, 2),data_format= \"channels_first\",  padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    #C2\n",
    "    model.add(Conv3D(32, (1, 3, 3), strides=(1, 1,1), padding='valid',data_format= \"channels_first\",  activation='relu'))#incertezza se togliere padding\n",
    "    model.add(keras.layers.MaxPooling3D(pool_size=(1,2, 2),data_format= \"channels_first\", ))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    #C3\n",
    "    model.add(Conv3D(64, (1,3, 3), strides=(1, 1,1), padding='valid',data_format= \"channels_first\",  activation='relu'))#incertezza se togliere padding\n",
    "    model.add(keras.layers.MaxPooling3D(pool_size=(1,2, 2),data_format= \"channels_first\", ))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256, activation='sigmoid'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    \n",
    "    opt_adam = keras.optimizers.Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt_adam, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def getFilesPathWithoutSeizure(indexSeizure, indexPat):\n",
    "    filesPath=[]\n",
    "    for i in range(0, nSeizure):\n",
    "        if(i!=indexSeizure):\n",
    "            filesPath.extend(interictalSpectograms[i])\n",
    "            filesPath.extend(preictalSpectograms[i])\n",
    "    shuffle(filesPath)\n",
    "    return filesPath\n",
    "\n",
    "\n",
    "def generate_arrays_for_training(indexPat, paths, start=0, end=100):\n",
    "    while True:\n",
    "        from_=int(len(paths)/100*start)\n",
    "        to_=int(len(paths)/100*end)\n",
    "        for i in range(from_, int(to_)):\n",
    "            f=paths[i]\n",
    "            x = np.load(PathSpectogramFolder+f)\n",
    "            x=np.array([x])\n",
    "            x=x.swapaxes(0,1)\n",
    "            if('P' in f):\n",
    "                y = np.repeat([[0,1]],x.shape[0], axis=0)\n",
    "            else:\n",
    "                y =np.repeat([[1,0]],x.shape[0], axis=0)\n",
    "            yield(x,y)\n",
    "            \n",
    "def generate_arrays_for_predict(indexPat, paths, start=0, end=100):\n",
    "    while True:\n",
    "        from_=int(len(paths)/100*start)\n",
    "        to_=int(len(paths)/100*end)\n",
    "        for i in range(from_, int(to_)):\n",
    "            f=paths[i]\n",
    "            x = np.load(PathSpectogramFolder+f)\n",
    "            x=np.array([x])\n",
    "            x=x.swapaxes(0,1)\n",
    "            yield(x)\n",
    "\n",
    "class EarlyStoppingByLossVal(keras.callbacks.Callback):\n",
    "    def __init__(self, monitor='val_loss', value=0.00001, verbose=0, lower=True):\n",
    "        super(keras.callbacks.Callback, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.value = value\n",
    "        self.verbose = verbose\n",
    "        self.lower=lower\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        current = logs.get(self.monitor)\n",
    "        if self.lower:\n",
    "            if current < self.value:\n",
    "                if self.verbose > 0:\n",
    "                    print(\"Epoch %05d: early stopping THR\" % epoch)\n",
    "                self.model.stop_training = True\n",
    "     #critical secton   \n",
    "\n",
    "def main():\n",
    "    print(\"START\")\n",
    "    if not os.path.exists(OutputPathModels):\n",
    "        os.makedirs(OutputPathModels)\n",
    "    loadParametersFromFile(\"PARAMETERS_CNN.txt\")\n",
    "    #callback=EarlyStopping(monitor='val_acc', min_delta=0, patience=0, verbose=0, mode='auto', baseline=None)\n",
    "    callback=EarlyStoppingByLossVal(monitor='val_acc', value=0.975, verbose=1, lower=False)\n",
    "    print(\"Parameters loaded\")\n",
    "    \n",
    "    for indexPat in range(0, len(patients)):\n",
    "        print('Patient '+patients[indexPat])\n",
    "        if not os.path.exists(OutputPathModels+\"ModelPat\"+patients[indexPat]+\"/\"):\n",
    "            os.makedirs(OutputPathModels+\"ModelPat\"+patients[indexPat]+\"/\")\n",
    "        loadSpectogramData(indexPat) \n",
    "        print('Spectograms data loaded')\n",
    "        \n",
    "        result='Patient '+patients[indexPat]+'\\n'     \n",
    "        result='Out Seizure, True Positive, False Positive, False negative, Second of Inter in Test, Sensitivity, FPR \\n'\n",
    "        for i in range(0, nSeizure):\n",
    "            print('SEIZURE OUT: '+str(i+1))\n",
    "            \n",
    "            print('Training start')  \n",
    "            model = createModel()\n",
    "            filesPath=getFilesPathWithoutSeizure(i, indexPat)\n",
    "            \n",
    "            model.fit_generator(generate_arrays_for_training(indexPat, filesPath, end=75), #end=75),#It take the first 75%\n",
    "                                validation_data=generate_arrays_for_training(indexPat, filesPath, start=75),#start=75), #It take the last 25%\n",
    "                                #steps_per_epoch=10000, epochs=10)\n",
    "                                steps_per_epoch=int((len(filesPath)-int(len(filesPath)/100*25))),#*25), \n",
    "                                validation_steps=int((len(filesPath)-int(len(filesPath)/100*75))),#*75),\n",
    "                                verbose=2,\n",
    "                                epochs=300, max_queue_size=2, shuffle=True, callbacks=[callback])# 100 epochs è meglio #aggiungere criterio di stop in base accuratezza\n",
    "            print('Training end')\n",
    "            \n",
    "            print('Testing start')\n",
    "            filesPath=interictalSpectograms[i]\n",
    "            interPrediction=model.predict_generator(generate_arrays_for_predict(indexPat, filesPath), max_queue_size=4, steps=len(filesPath))\n",
    "            filesPath=preictalRealSpectograms[i]\n",
    "            preictPrediction=model.predict_generator(generate_arrays_for_predict(indexPat, filesPath), max_queue_size=4, steps=len(filesPath))\n",
    "            print('Testing end')\n",
    "            \n",
    "\n",
    "            # Creates a HDF5 file \n",
    "            model.save(OutputPathModels+\"ModelPat\"+patients[indexPat]+\"/\"+'ModelOutSeizure'+str(i+1)+'.h5')\n",
    "            print(\"Model saved\")\n",
    "            \n",
    "            #to plot the model\n",
    "            #plot_model(model, to_file=\"CNNModel\", show_shapes=True, show_layer_names=True)\n",
    "            \n",
    "            if not os.path.exists(OutputPathModels+\"OutputTest\"+\"/\"):\n",
    "                os.makedirs(OutputPathModels+\"OutputTest\"+\"/\")\n",
    "            np.savetxt(OutputPathModels+\"OutputTest\"+\"/\"+\"Int_\"+patients[indexPat]+\"_\"+str(i+1)+\".csv\", interPrediction, delimiter=\",\")\n",
    "            np.savetxt(OutputPathModels+\"OutputTest\"+\"/\"+\"Pre_\"+patients[indexPat]+\"_\"+str(i+1)+\".csv\", preictPrediction, delimiter=\",\")\n",
    "            \n",
    "            secondsInterictalInTest=len(interictalSpectograms[i])*50*30#50 spectograms for file, 30 seconds for each spectogram\n",
    "            acc=0#accumulator\n",
    "            fp=0\n",
    "            tp=0\n",
    "            fn=0\n",
    "            lastTenResult=list()\n",
    "            \n",
    "            for el in interPrediction:\n",
    "                if(el[1]>0.5):\n",
    "                    acc=acc+1\n",
    "                    lastTenResult.append(1)\n",
    "                else:\n",
    "                    lastTenResult.append(0)\n",
    "                if(len(lastTenResult)>10):\n",
    "                    acc=acc-lastTenResult.pop(0)\n",
    "                if(acc>=8):\n",
    "                  fp=fp+1\n",
    "                  lastTenResult=list()\n",
    "                  acc=0\n",
    "            \n",
    "            lastTenResult=list()\n",
    "            for el in preictPrediction:\n",
    "                if(el[1]>0.5):\n",
    "                    acc=acc+1\n",
    "                    lastTenResult.append(1)\n",
    "                else:\n",
    "                    lastTenResult.append(0)\n",
    "                if(len(lastTenResult)>10):\n",
    "                    acc=acc-lastTenResult.pop(0)\n",
    "                if(acc>=8):\n",
    "                  tp=tp+1 \n",
    "                else:\n",
    "                    if(len(lastTenResult)==10):\n",
    "                       fn=fn+1 \n",
    "                       \n",
    "            sensitivity=tp/(tp+fn)\n",
    "            FPR=fp/(secondsInterictalInTest/(60*60))\n",
    "            \n",
    "            result=result+str(i+1)+','+str(tp)+','+str(fp)+','+str(fn)+','+str(secondsInterictalInTest)+','\n",
    "            result=result+str(sensitivity)+','+str(FPR)+'\\n'\n",
    "            print('True Positive, False Positive, False negative, Second of Inter in Test, Sensitivity, FPR')\n",
    "            print(str(tp)+','+str(fp)+','+str(fn)+','+str(secondsInterictalInTest)+','+str(sensitivity)+','+str(FPR))\n",
    "        with open(OutputPath, \"a+\") as myfile:\n",
    "            myfile.write(result)\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GKfMaG2Bm-4a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ogl1YOTcmdwm"
   },
   "outputs": [],
   "source": [
    "\n",
    "OutputPathModels=['/content/chbmit-1.0.0.physionet.org',\n",
    "                  '/content/chbmit-1.0.0.physionet.org'] \n",
    "def dataProc():\n",
    "    pat=[\"01\"]\n",
    "    nSeizure=[2]\n",
    "    secondsInterictalInTest=[7500,31500, 10500, 46500, 21000,10500]\n",
    "    threshold=[0.6,0.8, 0.4, 0.001, 0.3,0.3]\n",
    "    #totSens=0\n",
    "    #totFPR=0\n",
    "    for j in range(0,len(pat)):\n",
    "        sensResults=[]\n",
    "        FPRResults=[]\n",
    "        for k in range(0,2):\n",
    "            for i in range(0, nSeizure[j]):            \n",
    "                interPrediction=np.loadtxt(OutputPathModels[k]+\"OutputTest\"+\"/\"+\"Int_\"+pat[j]+\"_\"+str(i+1)+\".csv\",delimiter=',')\n",
    "                preictPrediction=np.loadtxt(OutputPathModels[k]+\"OutputTest\"+\"/\"+\"Pre_\"+pat[j]+\"_\"+str(i+1)+\".csv\",delimiter=',')\n",
    "                \n",
    "                acc=0#accumulator\n",
    "                fp=0\n",
    "                tp=0\n",
    "                fn=0\n",
    "                lastTenResult=list()\n",
    "                \n",
    "                for el in interPrediction:\n",
    "                    if(el[1]>threshold[j]):\n",
    "                        acc=acc+1\n",
    "                        lastTenResult.append(1)\n",
    "                    else:\n",
    "                        lastTenResult.append(0)\n",
    "                    if(len(lastTenResult)>10):\n",
    "                        acc=acc-lastTenResult.pop(0)\n",
    "                    if(acc>=8):\n",
    "                      fp=fp+1\n",
    "                      lastTenResult=list()\n",
    "                      acc=0\n",
    "                \n",
    "                lastTenResult=list()\n",
    "                for el in preictPrediction:\n",
    "                    if(el[1]>threshold[j]):\n",
    "                        acc=acc+1\n",
    "                        lastTenResult.append(1)\n",
    "                    else:\n",
    "                        lastTenResult.append(0)\n",
    "                    if(len(lastTenResult)>10):\n",
    "                        acc=acc-lastTenResult.pop(0)\n",
    "                    if(acc>=8):\n",
    "                      tp=tp+1 \n",
    "                    else:\n",
    "                        if(len(lastTenResult)==10):\n",
    "                           fn=fn+1 \n",
    "                           \n",
    "                sensitivity=tp/(tp+fn)*100\n",
    "                FPR=fp/(secondsInterictalInTest[j]/(60*60))\n",
    "                sensResults.append(sensitivity)\n",
    "                FPRResults.append(FPR)\n",
    "                \n",
    "        sdSENS=statistics.stdev(sensResults)\n",
    "        avSENS=statistics.mean(sensResults)\n",
    "        \n",
    "        sdFPR=statistics.stdev(FPRResults)\n",
    "        avFPR=statistics.mean(FPRResults)\n",
    "        print(pat[j]+\"   AVG_Sens= \"+str(avSENS)+\" +- \"+str(sdSENS)+\"   AVG_FPR= \"+str(avFPR)+\" +- \"+str(sdFPR))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "ZQf_CVOdrXEK",
    "outputId": "12225069-fe86-437d-ebf7-bee025772e19"
   },
   "outputs": [],
   "source": [
    "dataProc()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "courseProject.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
